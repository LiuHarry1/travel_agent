# =============================================================================
# Retrieval Service Environment Variables
# =============================================================================
# Copy this file to .env and configure the values according to your setup.
# This file documents all environment variables used by the retrieval-service.
#
# Note: Environment variables are case-insensitive in pydantic-settings.
# =============================================================================

# -----------------------------------------------------------------------------
# Milvus Vector Database Configuration
# -----------------------------------------------------------------------------
# Milvus connection settings for vector storage
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_USER=
MILVUS_PASSWORD=
MILVUS_COLLECTION_NAME=knowledge_base

# -----------------------------------------------------------------------------
# Embedding Models Configuration
# -----------------------------------------------------------------------------
# Comma-separated list of embedding models to use
# Format: "provider:model" or just "provider" (uses default model)
# Supported providers: qwen, openai, bge, bge-en, bge-zh, nemotron, nvidia, snowflake
# Examples:
#   - qwen:text-embedding-v2
#   - openai:text-embedding-3-small
#   - bge:BAAI/bge-large-en-v1.5
#   - bge-en:BAAI/bge-large-en-v1.5
#   - bge-zh:BAAI/bge-large-zh-v1.5
#   - nemotron:nvidia/llama-nemotron-embed-1b-v2
#   - snowflake:Snowflake/snowflake-arctic-embed-l
EMBEDDING_MODELS=qwen:text-embedding-v2

# -----------------------------------------------------------------------------
# Qwen/DashScope API Configuration
# -----------------------------------------------------------------------------
# API key for Qwen embedding models (DashScope)
# You can use either DASHSCOPE_API_KEY or QWEN_API_KEY
DASHSCOPE_API_KEY=
QWEN_API_KEY=

# Qwen LLM settings (for LLM filtering)
QWEN_BASE_URL=https://dashscope.aliyuncs.com/compatible-mode/v1
QWEN_MODEL=qwen-plus

# -----------------------------------------------------------------------------
# OpenAI API Configuration
# -----------------------------------------------------------------------------
# API key for OpenAI embedding models
OPENAI_API_KEY=

# Optional: Custom base URL for OpenAI-compatible APIs (e.g., proxy or custom endpoints)
# Default: https://api.openai.com/v1
OPENAI_BASE_URL=

# -----------------------------------------------------------------------------
# BGE Embedding Service API URLs
# -----------------------------------------------------------------------------
# General BGE API URL (used when provider is "bge")
# Example: http://localhost:8001
BGE_API_URL=http://localhost:8001

# English BGE API URL (used when provider is "bge-en")
# Example: http://10.150.10.120:6000
BGE_EN_API_URL=http://10.150.10.120:6000

# Chinese BGE API URL (used when provider is "bge-zh")
# Example: http://10.150.10.120:6001
BGE_ZH_API_URL=http://10.150.10.120:6001

# -----------------------------------------------------------------------------
# NVIDIA Nemotron Embedding Service API URL
# -----------------------------------------------------------------------------
# Full API endpoint URL for NVIDIA Nemotron embedding service
# Used when provider is "nemotron" or "nvidia"
# Example: http://10.150.10.120:6002/embed
NEMOTRON_API_URL=http://10.150.10.120:6002/embed

# -----------------------------------------------------------------------------
# Snowflake Arctic Embedding Service API URL
# -----------------------------------------------------------------------------
# Full API endpoint URL for Snowflake Arctic embedding service
# Used when provider is "snowflake"
# Example: http://10.150.10.120:6003/embed
SNOWFLAKE_API_URL=http://10.150.10.120:6003/embed

# -----------------------------------------------------------------------------
# Retrieval Pipeline Settings
# -----------------------------------------------------------------------------
# Number of results per embedding model
TOP_K_PER_MODEL=10

# Number of results to keep after rerank
RERANK_TOP_K=20

# Final number of results after LLM filtering
FINAL_TOP_K=10

# -----------------------------------------------------------------------------
# CORS Configuration
# -----------------------------------------------------------------------------
# CORS allowed origins (comma-separated)
# Default includes common localhost ports
CORS_ORIGINS=http://localhost:3000,http://localhost:5173,http://localhost:5174,http://localhost:5175,http://localhost:8080

# =============================================================================
# Notes:
# =============================================================================
# 1. For Qwen embeddings, you need to set either DASHSCOPE_API_KEY or QWEN_API_KEY
# 2. For OpenAI embeddings, you need to set OPENAI_API_KEY
# 3. For BGE embeddings, you need to set the appropriate BGE_API_URL based on your provider:
#    - bge: Use BGE_API_URL
#    - bge-en: Use BGE_EN_API_URL
#    - bge-zh: Use BGE_ZH_API_URL
# 4. For Nemotron/NVIDIA embeddings, set NEMOTRON_API_URL
# 5. For Snowflake embeddings, set SNOWFLAKE_API_URL
# 6. All API URLs should include the protocol (http:// or https://)
# 7. The EMBEDDING_MODELS variable supports multiple models separated by commas
# 8. Pipeline configuration is also stored in pipelines.yaml file
# =============================================================================
