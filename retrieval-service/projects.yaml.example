# Projects Configuration Example
# This file defines project-specific configurations for the retrieval service.
# Each project can have its own Milvus connection, embedding models, rerank service, and LLM settings.

# Default project name (used when project_name is not specified in API calls)
default: project1

# Project configurations
projects:
  # Example project 1: Development environment
  project1:
    # Milvus vector database configuration
    milvus:
      host: localhost
      port: 19530
      user: ""  # Optional: leave empty if not using authentication
      password: ""  # Optional: leave empty if not using authentication
      database: default  # Database name in Milvus
      collection: memory_doc_db  # Collection name in Milvus

    # Embedding models to use for retrieval
    # Format: "provider:model_name" or just "provider" (uses default model)
    # Supported providers: qwen, bge, openai
    # Default: qwen (uses text-embedding-v2)
    embedding_models:
      - qwen
      # - qwen:text-embedding-v2  # Explicit model name
      # - bge:BAAI/bge-large-en-v1.5
      # - openai:text-embedding-3-small

    # Rerank service configuration
    rerank:
      api_url: ""  # Rerank API endpoint (leave empty to use mock implementation)
      model: ""  # Optional: rerank model name
      timeout: 30  # Request timeout in seconds

    # LLM filter configuration (for filtering irrelevant chunks)
    llm_filter:
      # API key can use environment variable: env:VAR_NAME
      api_key: env:DASHSCOPE_API_KEY  # or provide directly: "sk-xxxxx"
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      model: qwen-plus

    # Retrieval pipeline parameters
    retrieval:
      top_k_per_model: 10  # Number of results per embedding model
      rerank_top_k: 20  # Number of results to keep after rerank
      final_top_k: 10  # Final number of results after LLM filtering

    # Chunk size limits for each stage
    chunk_sizes:
      initial_search: 100  # Max chunks from initial search per model
      rerank_input: 50  # Max chunks to send to rerank
      llm_filter_input: 20  # Max chunks to send to LLM filter

  # Example project 2: Production environment
  project2:
    milvus:
      host: milvus-prod.example.com
      port: 19530
      user: admin
      password: env:MILVUS_PASSWORD  # Use environment variable for sensitive data
      database: default
      collection: memory_doc_db

    embedding_models:
      - qwen
      # - bge:BAAI/bge-large-en-v1.5

    rerank:
      api_url: http://rerank-service:8002/rerank
      model: bge-reranker-base
      timeout: 60

    llm_filter:
      api_key: env:DASHSCOPE_API_KEY
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      model: qwen-max

    retrieval:
      top_k_per_model: 15
      rerank_top_k: 30
      final_top_k: 15

    chunk_sizes:
      initial_search: 150
      rerank_input: 75
      llm_filter_input: 30

  # Example project 3: Testing environment
  test_project:
    milvus:
      host: localhost
      port: 19530
      user: ""
      password: ""
      database: default
      collection: memory_doc_db

    embedding_models:
      - qwen

    rerank:
      api_url: ""  # Use mock rerank for testing
      model: ""
      timeout: 30

    llm_filter:
      api_key: env:TEST_DASHSCOPE_API_KEY
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      model: qwen-plus

    retrieval:
      top_k_per_model: 5
      rerank_top_k: 10
      final_top_k: 5

    chunk_sizes:
      initial_search: 50
      rerank_input: 25
      llm_filter_input: 10

