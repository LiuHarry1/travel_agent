# Pipelines Configuration Example
# This file defines pipeline-specific configurations for the retrieval service.
# Each pipeline can have its own Milvus connection, embedding models, rerank service, and LLM settings.

# Default pipeline name (used when pipeline_name is not specified in API calls)
default: memory

# Pipeline configurations
pipelines:
  # Example pipeline 1: Development environment
  memory:
    # Milvus vector database configuration
    milvus:
      host: localhost
      port: 19530
      user: ""  # Optional: leave empty if not using authentication
      password: ""  # Optional: leave empty if not using authentication
      database: default  # Database name in Milvus
      collection: memory_doc_db  # Default collection name (used if not specified in embedding_models)

    # Embedding models to use for retrieval
    # Format options:
    #   - Simple: "qwen" (uses default collection)
    #   - With model: "qwen:text-embedding-v2" (uses default collection)
    #   - With collection: "qwen:memory_doc_db" (qwen model -> memory_doc_db collection)
    #   - Full: "qwen:text-embedding-v2:memory_doc_db" (provider:model:collection)
    #   - Object format:
    #     - model: "qwen"
    #       collection: "memory_doc_db"
    embedding_models:
      - qwen  # Uses default collection: memory_doc_db
      # - qwen:text-embedding-v2  # Explicit model name, uses default collection
      # - qwen:memory_doc_db  # qwen model -> memory_doc_db collection
      # - qwen:text-embedding-v2:memory_doc_db  # Full format
      # - model: "bge"
      #   collection: "bge_collection"  # Object format for different collection
      # - bge:BAAI/bge-large-en-v1.5:bge_collection  # BGE model with specific collection
      # - openai:text-embedding-3-small:openai_collection  # OpenAI model with specific collection

    # Rerank service configuration
    rerank:
      api_url: ""  # Rerank API endpoint (leave empty to use mock implementation)
      model: ""  # Optional: rerank model name
      timeout: 30  # Request timeout in seconds

    # LLM filter configuration (for filtering irrelevant chunks)
    llm_filter:
      # API key can use environment variable: env:VAR_NAME
      api_key: env:DASHSCOPE_API_KEY  # or provide directly: "sk-xxxxx"
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      model: qwen-plus

    # Retrieval pipeline parameters
    retrieval:
      top_k_per_model: 10  # Number of results per embedding model
      rerank_top_k: 20  # Number of results to keep after rerank
      final_top_k: 10  # Final number of results after LLM filtering

    # Chunk size limits for each stage
    chunk_sizes:
      initial_search: 100  # Max chunks from initial search per model
      rerank_input: 50  # Max chunks to send to rerank
      llm_filter_input: 20  # Max chunks to send to LLM filter

  # Example pipeline 2: Multi-model with different collections
  multi_model:
    milvus:
      host: localhost
      port: 19530
      user: ""
      password: ""
      database: default
      collection: default_collection  # Default collection

    # Each embedding model uses its own collection
    embedding_models:
      - qwen:qwen_collection  # qwen model -> qwen_collection
      - bge:bge_collection  # bge model -> bge_collection
      - openai:openai_collection  # openai model -> openai_collection

    rerank:
      api_url: http://rerank-service:8002/rerank
      model: bge-reranker-base
      timeout: 60

    llm_filter:
      api_key: env:DASHSCOPE_API_KEY
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      model: qwen-max

    retrieval:
      top_k_per_model: 15
      rerank_top_k: 30
      final_top_k: 15

    chunk_sizes:
      initial_search: 150
      rerank_input: 75
      llm_filter_input: 30

  # Example pipeline 3: Testing environment
  test_pipeline:
    milvus:
      host: localhost
      port: 19530
      user: ""
      password: ""
      database: default
      collection: test_collection

    embedding_models:
      - qwen  # Uses test_collection

    rerank:
      api_url: ""  # Use mock rerank for testing
      model: ""
      timeout: 30

    llm_filter:
      api_key: env:TEST_DASHSCOPE_API_KEY
      base_url: https://dashscope.aliyuncs.com/compatible-mode/v1
      model: qwen-plus

    retrieval:
      top_k_per_model: 5
      rerank_top_k: 10
      final_top_k: 5

    chunk_sizes:
      initial_search: 50
      rerank_input: 25
      llm_filter_input: 10


